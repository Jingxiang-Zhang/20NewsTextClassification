{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee40471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import load_data\n",
    "import scipy\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from joblib import dump, load\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a4af6",
   "metadata": {},
   "source": [
    "###### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8724991d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_label = load_data.read_map(load_data.test_map_path)\n",
    "train_data, train_label = load_data.read_data(load_data.train_data_path, load_data.train_label_path)\n",
    "test_data, test_label = load_data.read_data(load_data.test_data_path, load_data.test_label_path)\n",
    "words_list = load_data.read_words(load_data.vocabulary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4b0b2",
   "metadata": {},
   "source": [
    "###### combine train data and test data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ed334fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine(train_data, train_label, test_data, test_label):\n",
    "    ## combine the train data and test data together\n",
    "    train_data = np.asarray(train_data, dtype=object)\n",
    "    test_data = np.asarray(test_data, dtype=object)\n",
    "    data = np.concatenate([train_data, test_data])\n",
    "    label = np.concatenate([train_label, test_label])\n",
    "    return data, label\n",
    "    \n",
    "\n",
    "def select_data(data, label, source_domain, target_domain):\n",
    "    source_loc = []\n",
    "    target_loc = []\n",
    "    for i in range(len(source_domain)):\n",
    "        source_loc_temp = list()\n",
    "        for j in range(len(source_domain[i])):\n",
    "            for key, value in map_label.items():\n",
    "                if value == source_domain[i][j]:\n",
    "                    source_loc_temp.append(key)\n",
    "                    break\n",
    "        source_loc.append(source_loc_temp) \n",
    "        \n",
    "        target_loc_temp = list()\n",
    "        for j in range(len(target_domain[i])):\n",
    "            for key, value in map_label.items():\n",
    "                if value == target_domain[i][j]:\n",
    "                    target_loc_temp.append(key)\n",
    "                    break\n",
    "        target_loc.append(target_loc_temp)\n",
    "\n",
    "    source_data = np.empty(shape=(0,), dtype=np.object)\n",
    "    source_label = np.empty(shape=(0,), dtype=np.int32)\n",
    "    target_data = np.empty(shape=(0,), dtype=np.object)\n",
    "    target_label = np.empty(shape=(0,), dtype=np.int32)\n",
    "    for i, loc_list in enumerate(source_loc):\n",
    "        for loc in loc_list:\n",
    "            d = data[label==loc]\n",
    "            l = np.ones(shape=(len(d))) * i\n",
    "            source_data = np.concatenate([source_data, d])\n",
    "            source_label = np.concatenate([source_label, l])\n",
    "    for i, loc_list in enumerate(target_loc):\n",
    "        for loc in loc_list:\n",
    "            d = data[label==loc]\n",
    "            l = np.ones(shape=(len(d))) * i\n",
    "            target_data = np.concatenate([target_data, d])\n",
    "            target_label = np.concatenate([target_label, l])        \n",
    "    return source_data, target_data, source_label, target_label\n",
    "\n",
    "data, label = combine(train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a9ee8",
   "metadata": {},
   "source": [
    "###### define statistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b7d709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def compare_prediction(prediction, label, class_number=20):\n",
    "    ratio_list = list()\n",
    "    for i in range(class_number):\n",
    "        i_label_index = label==i\n",
    "        class_number = np.sum(i_label_index)\n",
    "        correct_prediction = np.sum(prediction[i_label_index] == i)\n",
    "        ratio = correct_prediction / class_number\n",
    "        ratio_list.append(ratio)\n",
    "    return np.asarray(ratio_list)\n",
    "\n",
    "\n",
    "def save_to_file(method_name, ratio_list, accuracy, domain_name, filename=\"save.xlsx\"):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_excel(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[\"method\", *domain_name, \"sum\"])\n",
    "    df.loc[len(df)] = [method_name, *ratio_list, accuracy]\n",
    "    df.to_excel(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7ba2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain_name = [\"comp\", \"rec\", \"sci\", \"talk\"]\n",
    "\n",
    "source_domain = [[\"comp.graphics\",\"comp.os.ms-windows.misc\"], \n",
    "                 [\"rec.autos\",\"rec.motorcycles\"], \n",
    "                 [\"sci.crypt\",\"sci.electronics\"], \n",
    "                 [\"talk.politics.guns\",\"talk.politics.mideast\"]]\n",
    "target_domain = [[\"comp.sys.ibm.pc.hardware\",\"comp.sys.mac.hardware\",\"comp.windows.x\"], \n",
    "                 [\"rec.sport.baseball\",\"rec.sport.hockey\"],\n",
    "                 [\"sci.med\", \"sci.space\"],\n",
    "                 [\"talk.politics.misc\", \"talk.religion.misc\"]]\n",
    "\n",
    "source_data, target_data, source_label, target_label = select_data(data, label, source_domain, target_domain)\n",
    "# target_data, target_label = select_data(data, label, target_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac496f",
   "metadata": {},
   "source": [
    "#### Test on SA - SVM\n",
    "\n",
    "since this model is inductive, the feature domain of the source and target data domain are not the same. We can not use SA. But however, I will first try this method, and the try to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84d205",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from adapt.feature_based import SA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def SVM_SSL(name, **kwargs):\n",
    "    \"\"\"\n",
    "    test for one SA SVM method\n",
    "    \"\"\"\n",
    "    source_data_matrix = load_data.to_scipy_sparse_matrix(source_data, len(words_list)+1)\n",
    "    target_data_matrix = load_data.to_scipy_sparse_matrix(target_data, len(words_list)+1)\n",
    "    \n",
    "    svc = SVC(**kwargs)\n",
    "    model_path = \"model/TL/\"+name+\".joblib\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"load \" + name + \" model\")\n",
    "        svc = load(model_path)\n",
    "        print(\"loading complete\")\n",
    "    else:\n",
    "        print(\"train \" + name + \" model\")\n",
    "        svc.fit(source_data_matrix, source_label)\n",
    "        dump(svc, model_path) \n",
    "        print(\"training complete\")\n",
    "    \n",
    "    target_prediction = svc.predict(target_data_matrix)\n",
    "    target_accuracy = np.sum(target_prediction == target_label) / len(target_label)\n",
    "    print(\"accuracy on target domain is: {:.3f}\".format(target_accuracy))\n",
    "    ratio_list = compare_prediction(target_prediction, target_label, len(target_domain))\n",
    "    save_to_file(name, ratio_list, target_accuracy, domain_name, \"TL_none.xlsx\")\n",
    "    \n",
    "    source_data_matrix = source_data_matrix.toarray()\n",
    "    target_data_matrix = target_data_matrix.toarray()\n",
    "    \n",
    "    model = SA(SVC(**kwargs), Xt=target_data_matrix, random_state=0)\n",
    "    model_path = \"model/TL/TL_\"+name+\".joblib\"\n",
    "    model.fit(source_data_matrix, source_label)\n",
    "    print(\"this model can't be save, it has 10 GB\")\n",
    "        \n",
    "    # model.fit(source_data_matrix, source_label)\n",
    "    target_prediction = model.predict(target_data_matrix)\n",
    "    target_accuracy = np.sum(target_prediction == target_label) / len(target_label)\n",
    "    print(\"accuracy on target domain is for transfer learing SA: {:.3f}\".format(target_accuracy))\n",
    "    ratio_list = compare_prediction(target_prediction, target_label, len(target_domain))\n",
    "    save_to_file(name, ratio_list, target_accuracy, domain_name, \"TL_sa.xlsx\")\n",
    "\n",
    "SVM_SSL(\"SA_SVM_linear\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec1cb9",
   "metadata": {},
   "source": [
    "#### feature analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3f84e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are total 61189 features for each data\n",
      "41799 features are used in the source domain, and 43969 features are used in the target domain\n",
      "27364 features are used for all the domain\n",
      "58404 features are used in at least one domain\n",
      "when n >= 50, 3963 features are used in the source domain, and 4118 features are used in the target domain\n",
      "when n >= 50, 5212 features are used in at least one domain\n"
     ]
    }
   ],
   "source": [
    "def feature_analyse():\n",
    "    source_data_matrix = load_data.to_scipy_sparse_matrix(source_data, len(words_list)+1)\n",
    "    target_data_matrix = load_data.to_scipy_sparse_matrix(target_data, len(words_list)+1)\n",
    "    source_data_matrix = source_data_matrix.toarray()\n",
    "    target_data_matrix = target_data_matrix.toarray()\n",
    "    print(\"there are total {} features for each data\".format(len(source_data_matrix[0])))\n",
    "    \n",
    "    feature_source = np.sum(source_data_matrix, axis=0) >= 1\n",
    "    feature_target = np.sum(target_data_matrix, axis=0) >= 1\n",
    "    print(\"{} features are used in the source domain, and {} features are used in the \"\n",
    "         \"target domain\".format(np.sum(feature_source), np.sum(feature_target)))\n",
    "    feature_common = np.bitwise_and(feature_source, feature_target)\n",
    "    print(\"{} features are used for all the domain\".format(np.sum(feature_common)))\n",
    "    feature_common = np.bitwise_or(feature_source, feature_target)\n",
    "    print(\"{} features are used in at least one domain\".format(np.sum(feature_common)))\n",
    "    \n",
    "    feature_source = np.sum(source_data_matrix, axis=0) >= 50\n",
    "    feature_target = np.sum(target_data_matrix, axis=0) >= 50\n",
    "    print(\"when n >= 50, {} features are used in the source domain, and {} features are used in the \"\n",
    "         \"target domain\".format(np.sum(feature_source), np.sum(feature_target)))\n",
    "    feature_common = np.bitwise_or(feature_source, feature_target)\n",
    "    print(\"when n >= 50, {} features are used in at least one domain\".format(np.sum(feature_common)))\n",
    "    \n",
    "feature_analyse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d40ab4",
   "metadata": {},
   "source": [
    "#### pick up the common domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0061e155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def common_feature(minimal_number):\n",
    "    source_data_matrix = load_data.to_scipy_sparse_matrix(source_data, len(words_list)+1)\n",
    "    target_data_matrix = load_data.to_scipy_sparse_matrix(target_data, len(words_list)+1)\n",
    "    source_data_matrix = source_data_matrix.toarray()\n",
    "    target_data_matrix = target_data_matrix.toarray()\n",
    "    # pick up the features that commonly used in source domain and target domain\n",
    "    feature_source = np.sum(source_data_matrix, axis=0) >= minimal_number\n",
    "    feature_target = np.sum(target_data_matrix, axis=0) >= minimal_number\n",
    "    feature_common = np.bitwise_or(feature_source, feature_target)\n",
    "    \n",
    "    feature_one = np.bitwise_and(np.sum(source_data_matrix, axis=0) >= 1, \n",
    "                                 np.sum(target_data_matrix, axis=0) >= 1)\n",
    "    feature_common = np.bitwise_and(feature_common, feature_one)\n",
    "    \n",
    "    common_source_data = source_data_matrix[:, feature_common]\n",
    "    common_target_data = target_data_matrix[:, feature_common]\n",
    "    return common_source_data, common_target_data\n",
    "    \n",
    "common_source_data, common_target_data = common_feature(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd2179",
   "metadata": {},
   "source": [
    "#### separate the target domain data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f149cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def separate():\n",
    "    print(\"this code can only be runned once!\")\n",
    "    length = common_target_data.shape[0]\n",
    "    index = np.random.permutation(length)\n",
    "    index_train = index[:length//2]\n",
    "    index_test = index[length//2:]\n",
    "    data_train = common_target_data[index_train]\n",
    "    data_test = common_target_data[index_test]\n",
    "    label_train = target_label[index_train]\n",
    "    label_test = target_label[index_test]\n",
    "    return data_train, data_test, label_train, label_test\n",
    "\n",
    "common_target_data, common_target_data_test, target_label, target_label_test = separate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86feb535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7735, 4929)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_source_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4374d6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4140, 4929)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb03975",
   "metadata": {},
   "source": [
    "#### Test TL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f706bfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from adapt.feature_based import SA\n",
    "from adapt.instance_based import IWC\n",
    "from adapt.instance_based import TrAdaBoost\n",
    "from scipy import sparse\n",
    "\n",
    "def none_TL(name, model):\n",
    "    \"\"\"\n",
    "    test for one SA SVM method\n",
    "    \"\"\"\n",
    "    common_source_data_sparse = sparse.csr_matrix(common_source_data)\n",
    "    model.fit(common_source_data_sparse, source_label)\n",
    "    target_prediction = model.predict(common_target_data_test)\n",
    "    target_accuracy = np.sum(target_prediction == target_label_test) / len(target_label_test)\n",
    "    print(\"accuracy on target domain is: {:.3f}\".format(target_accuracy))\n",
    "    ratio_list = compare_prediction(target_prediction, target_label_test, len(target_domain))\n",
    "    save_to_file(name, ratio_list, target_accuracy, domain_name, \"TL_none.xlsx\")\n",
    "\n",
    "def SA_method(name, model):\n",
    "    model = SA(model, Xt=common_target_data, yt=target_label, random_state=0)\n",
    "    model.fit(common_source_data, source_label)\n",
    "    target_prediction = model.predict(common_target_data_test)\n",
    "    target_accuracy = np.sum(target_prediction == target_label_test) / len(target_label_test)\n",
    "    print(\"accuracy on target domain is for transfer learing SA: {:.3f}\".format(target_accuracy))\n",
    "    ratio_list = compare_prediction(target_prediction, target_label_test, len(target_domain))\n",
    "    save_to_file(name, ratio_list, target_accuracy, domain_name, \"TL_sa.xlsx\")\n",
    "\n",
    "def Boost_method(name, model):\n",
    "    model = TrAdaBoost(model, Xt=common_target_data, yt=target_label,n_estimators=5,random_state=0)\n",
    "    model.fit(common_source_data, source_label)\n",
    "    target_prediction = model.predict(common_target_data_test)\n",
    "    target_accuracy = np.sum(target_prediction == target_label_test) / len(target_label_test)\n",
    "    print(\"accuracy on target domain is for transfer learing SA: {:.3f}\".format(target_accuracy))\n",
    "    ratio_list = compare_prediction(target_prediction, target_label_test, len(target_domain))\n",
    "    save_to_file(name, ratio_list, target_accuracy, domain_name, \"TL_boost.xlsx\")\n",
    "\n",
    "\n",
    "# none_TL(\"SA_SVM_linear\", model=SVC(kernel=\"linear\"))\n",
    "# SA_method(\"SA_SVM_linear\", model=SVC(kernel=\"linear\"))\n",
    "# Boost_method(\"SA_SVM_linear\", model=SVC(kernel=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a84663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def start_TL_test(method):\n",
    "    try:\n",
    "        method(\"SVM_linear\", model=SVC(kernel=\"linear\"))\n",
    "    except Exception as e:\n",
    "        print(\"error happened when execute SVM_linear: \", str(e))\n",
    "\n",
    "    try:\n",
    "        method(\"MLR_OVR\", model=LogisticRegression(multi_class='ovr', max_iter=500))\n",
    "    except Exception as e:\n",
    "        print(\"error happened when execute MLR_OVR: \", str(e))\n",
    "    \n",
    "    try:\n",
    "        method(\"Multinomial_Naive_Bayes\", model=MultinomialNB())\n",
    "    except Exception as e:\n",
    "        print(\"error happened when execute Multinomial_Naive_Bayes: \", str(e))\n",
    "    \n",
    "    try:\n",
    "        method(\"decision_tree\", model=DecisionTreeClassifier())\n",
    "    except Exception as e:\n",
    "        print(\"error happened when execute decision_tree: \", str(e))\n",
    "\n",
    "    try:\n",
    "        method(\"random_forest\", model=RandomForestClassifier())\n",
    "    except Exception as e:\n",
    "        print(\"error happened when execute random_forest: \", str(e))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d4b0b917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start none TL: \n",
      "accuracy on target domain is: 0.522\n",
      "accuracy on target domain is: 0.540\n",
      "accuracy on target domain is: 0.670\n",
      "accuracy on target domain is: 0.395\n",
      "accuracy on target domain is: 0.537\n",
      "start SA: \n",
      "Fit transform...\n",
      "Fit Estimator...\n",
      "accuracy on target domain is for transfer learing SA: 0.489\n",
      "Fit transform...\n",
      "Fit Estimator...\n",
      "accuracy on target domain is for transfer learing SA: 0.504\n",
      "Fit transform...\n",
      "Fit Estimator...\n",
      "error happened when execute Multinomial_Naive_Bayes:  Negative values in data passed to MultinomialNB (input X)\n",
      "Fit transform...\n",
      "Fit Estimator...\n",
      "accuracy on target domain is for transfer learing SA: 0.302\n",
      "Fit transform...\n",
      "Fit Estimator...\n",
      "accuracy on target domain is for transfer learing SA: 0.342\n",
      "start TrAdaBoost: \n",
      "Iteration 0 - Error: 0.0010\n",
      "Iteration 1 - Error: 0.0005\n",
      "Iteration 2 - Error: 0.0002\n",
      "Iteration 3 - Error: 0.0004\n",
      "Iteration 4 - Error: 0.0004\n",
      "accuracy on target domain is for transfer learing SA: 0.861\n",
      "Iteration 0 - Error: 0.0514\n",
      "Iteration 1 - Error: 0.0689\n",
      "Iteration 2 - Error: 0.0781\n",
      "Iteration 3 - Error: 0.0743\n",
      "Iteration 4 - Error: 0.0685\n",
      "accuracy on target domain is for transfer learing SA: 0.898\n",
      "Iteration 0 - Error: 0.0870\n",
      "Iteration 1 - Error: 0.1474\n",
      "Iteration 2 - Error: 0.0771\n",
      "Iteration 3 - Error: 0.2021\n",
      "Iteration 4 - Error: 0.1115\n",
      "accuracy on target domain is for transfer learing SA: 0.929\n",
      "Iteration 0 - Error: 0.0001\n",
      "Iteration 1 - Error: 0.0001\n",
      "Iteration 2 - Error: 0.0000\n",
      "Iteration 3 - Error: 0.0000\n",
      "Iteration 4 - Error: 0.0000\n",
      "accuracy on target domain is for transfer learing SA: 0.657\n",
      "Iteration 0 - Error: 0.1678\n",
      "Iteration 1 - Error: 0.1725\n",
      "Iteration 2 - Error: 0.1793\n",
      "Iteration 3 - Error: 0.1887\n",
      "Iteration 4 - Error: 0.1973\n",
      "accuracy on target domain is for transfer learing SA: 0.911\n"
     ]
    }
   ],
   "source": [
    "print(\"Mind that all the transfer learning model is extremely huge, I can't save those model\")\n",
    "print(\"start none TL: \")\n",
    "start_TL_test(none_TL)\n",
    "print(\"start SA: \")\n",
    "start_TL_test(SA_method)\n",
    "print(\"start TrAdaBoost: \")\n",
    "start_TL_test(Boost_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e97d8",
   "metadata": {},
   "source": [
    "#### Test on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "799fd3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Final_Tr_Ada_Boost model\n",
      "setting\n",
      "loading complete\n",
      "accuracy on source domain is : 0.796\n",
      "accuracy on target domain is : 0.983\n",
      "Est = 0.221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def Boost_Bayes():\n",
    "    model = TrAdaBoost(MultinomialNB(), Xt=common_target_data, yt=target_label,n_estimators=5,random_state=0)\n",
    "    name = \"Final_Tr_Ada_Boost\"\n",
    "    model_path = \"model/TL/\"+name+\".joblib\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"load \" + name + \" model\")\n",
    "        model = load(model_path)\n",
    "        print(\"loading complete\")\n",
    "    else:\n",
    "        print(\"train \" + name + \" model\")\n",
    "        model.fit(common_source_data, source_label)\n",
    "        dump(model, model_path) \n",
    "        print(\"training complete\")\n",
    "        \n",
    "    # model.fit(common_source_data, source_label)\n",
    "    \n",
    "    source_prediction = model.predict(common_source_data)\n",
    "    source_accuracy = np.sum(source_prediction == source_label) / len(source_label)\n",
    "    print(\"accuracy on source domain is : {:.3f}\".format(source_accuracy))\n",
    "    target_prediction = model.predict(common_target_data)\n",
    "    target_accuracy = np.sum(target_prediction == target_label) / len(target_label)\n",
    "    print(\"accuracy on target domain is : {:.3f}\".format(target_accuracy))\n",
    "    print(\"Est = {:.3f}\".format(2-source_accuracy-target_accuracy))\n",
    "    \n",
    "Boost_Bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6926db",
   "metadata": {},
   "source": [
    "#### error bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09ec7deb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error bound is: 0.540\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 0.651\n",
    "N = 7735+4140+4140\n",
    "dvc = 2\n",
    "theta = 0.1\n",
    "\n",
    "error_bound = 2*(1-0.5)*(0.255+0.5*0.1) + 4*math.sqrt(alpha*alpha/beta + (1-alpha)**2/(1-beta))*\\\n",
    "        math.sqrt(2/N*dvc*np.log(2*N+2)+2/N*np.log(8/theta))\n",
    "\n",
    "print(\"error bound is: {:.3f}\".format(error_bound))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
